{
  "comments": [
    {
      "key": {
        "uuid": "72593c72_751d13c3",
        "filename": "client/includes/Hooks/DataUpdateHookHandlers.php",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 4699
      },
      "writtenOn": "2019-06-28T10:13:58Z",
      "side": 1,
      "message": "If we get the current usages from a replica, isn’t it possible that we incorrectly conclude that no changes are needed and skip the update even when it would have been necessary?\n\nFor example: An anonymous user blanks a page and is immediately reverted by some patrolling bot. When the patrol bot’s edit is processed, the replica hasn’t caught up with the anonymous edit yet and still has all the entity usages for the page; we conclude that the entity usages didn’t change, don’t schedule a job, and the empty entity usages remain in the master (and, eventually, in the replica too).",
      "revId": "bc58fc0be58af61eb53840d2d04cc7577edc5918",
      "serverId": "e9e9afe9-4712-486d-8885-f54b72dd1951",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "f143c249_9561b237",
        "filename": "client/includes/Hooks/DataUpdateHookHandlers.php",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 920
      },
      "writtenOn": "2019-06-28T10:25:11Z",
      "side": 1,
      "message": "I saw that might happen but the chance of it happening is really low (the lag is usually less than one second, the time between any edit is waaay more than that). Specially given that these data are secondary data and will be fixed and reparsed in the next edit in case that happens (which will be less than 0.1%)",
      "parentUuid": "72593c72_751d13c3",
      "revId": "bc58fc0be58af61eb53840d2d04cc7577edc5918",
      "serverId": "e9e9afe9-4712-486d-8885-f54b72dd1951",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "e6016d35_86bfc1cd",
        "filename": "client/includes/Hooks/DataUpdateHookHandlers.php",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 4699
      },
      "writtenOn": "2019-06-28T11:21:41Z",
      "side": 1,
      "message": "This code runs on every edit on every client wiki. I don’t think a “really low” chance of this happening is good enough, nor is relying on what the replication lag “usually” is. Between tools and bots, there are plenty of cases where the same page may be  edited multiple times in the same second; at the same time, if there are no other edits to the page after that, it might take up to thirty days for the next parser cache update (I think).\n\nSince one of the arguments the hook passes to us is a $revId (presumably the one that triggered this update, if not null), we might be able to check if the replica already has a row for this revision, and in that case assume it’s sufficiently up-to-date. (Though I’m not sure if that would be enough.) But I have a feeling that we should just bite the bullet and use a master connection here. (Or is this a context where we’re not allowed to contact the master because it might be a GET request?)",
      "parentUuid": "f143c249_9561b237",
      "revId": "bc58fc0be58af61eb53840d2d04cc7577edc5918",
      "serverId": "e9e9afe9-4712-486d-8885-f54b72dd1951",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4132143a_9a7c48a2",
        "filename": "client/includes/Hooks/DataUpdateHookHandlers.php",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 920
      },
      "writtenOn": "2019-06-28T11:39:58Z",
      "side": 1,
      "message": "\u003eI don’t think a “really low” chance of this happening is good enough, nor is relying on what the replication lag “usually” is.\n\nLet me explain this way: 1- If replication lag for any of replicas is more than 5 seconds, the master goes read-only and stops any edits. 2- Bots and gadgets should and almost all of them have throttling enabled, pywikibot for example waits around 10 seconds between every edit. Same goes for gadgets, the only exception here is wikidata\u0027s old term box that\u0027s actually biting us in another area.\n\nI have a suggestion to move forward, let\u0027s query rc table of a hot wiki (commons, enwiki) and check if the timestamp of at least two edits is the same down to the second or even five, on the same page. Get the total number and check the ratio to get the feeling if that\u0027s something worth fixing.",
      "parentUuid": "e6016d35_86bfc1cd",
      "revId": "bc58fc0be58af61eb53840d2d04cc7577edc5918",
      "serverId": "e9e9afe9-4712-486d-8885-f54b72dd1951",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "69f094ab_6023d9c3",
        "filename": "client/includes/Hooks/DataUpdateHookHandlers.php",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 4699
      },
      "writtenOn": "2019-06-28T11:47:02Z",
      "side": 1,
      "message": "\u003e I have a suggestion to move forward, let\u0027s query rc table of a hot wiki (commons, enwiki) and check if the timestamp of at least two edits is the same down to the second or even five, on the same page. Get the total number and check the ratio to get the feeling if that\u0027s something worth fixing.\n\nEight hundred and something edits to the same page within less than two seconds on enwiki. I just rebooted so I no longer have the exact number, but I already ran the query. Took some 16 minutes on the stats machines.",
      "parentUuid": "4132143a_9a7c48a2",
      "revId": "bc58fc0be58af61eb53840d2d04cc7577edc5918",
      "serverId": "e9e9afe9-4712-486d-8885-f54b72dd1951",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "60d40235_bcbab2d8",
        "filename": "client/includes/Hooks/DataUpdateHookHandlers.php",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 920
      },
      "writtenOn": "2019-06-28T11:51:56Z",
      "side": 1,
      "message": "total number of rows in enwiki is 7639658, which means the ratio is at most 0.012%",
      "parentUuid": "69f094ab_6023d9c3",
      "revId": "bc58fc0be58af61eb53840d2d04cc7577edc5918",
      "serverId": "e9e9afe9-4712-486d-8885-f54b72dd1951",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "fcb6a44a_5a585068",
        "filename": "client/includes/Hooks/DataUpdateHookHandlers.php",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 920
      },
      "writtenOn": "2019-06-28T11:53:52Z",
      "side": 1,
      "message": "And only 9% of those edits actually change the entity usage (the error rate would be 0.001% then) also keep in mind the replication lag is not always two seconds. Most of cases it\u0027s around several hundred milliseconds",
      "parentUuid": "60d40235_bcbab2d8",
      "revId": "bc58fc0be58af61eb53840d2d04cc7577edc5918",
      "serverId": "e9e9afe9-4712-486d-8885-f54b72dd1951",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "f898e2d3_d1d11a35",
        "filename": "client/includes/Hooks/DataUpdateHookHandlers.php",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 4699
      },
      "writtenOn": "2019-06-28T14:48:59Z",
      "side": 1,
      "message": "Even if only 9% of those edits change the entity usage that’s dozens of missed updates per month. I don’t think this is acceptable.\n\nI ran the query again, by the way:\n\n MariaDB [enwiki]\u003e SELECT COUNT(*) FROM recentchanges AS rc1 JOIN recentchanges AS rc2 ON rc1.rc_cur_id \u003d rc2.rc_cur_id WHERE rc1.rc_type \u003d 0 AND rc2.rc_type \u003d 0 AND rc2.rc_timestamp \u003e rc1.rc_timestamp AND rc2.rc_timestamp - rc1.rc_timestamp \u003c 2;\n +----------+\n | COUNT(*) |\n +----------+\n |      851 |\n +----------+\n 1 row in set (16 min 14.54 sec)",
      "parentUuid": "fcb6a44a_5a585068",
      "revId": "bc58fc0be58af61eb53840d2d04cc7577edc5918",
      "serverId": "e9e9afe9-4712-486d-8885-f54b72dd1951",
      "unresolved": true
    }
  ]
}